{
  "best_metric": 4.057548999786377,
  "best_model_checkpoint": "/content/.cache/checkpoints/seller/checkpoint-2000",
  "epoch": 1.942690626517727,
  "eval_steps": 200,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04856726566294318,
      "grad_norm": 2.3956360816955566,
      "learning_rate": 4.6888206734679135e-05,
      "loss": 7.0748,
      "step": 50
    },
    {
      "ema_loss": 7.0748,
      "epoch": 0.04856726566294318,
      "grad_norm": 2.3956360816955566,
      "learning_rate": 4.6888206734679135e-05,
      "loss": 7.0748,
      "min_ema_loss": 7.0748,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.09713453132588636,
      "grad_norm": 0.8234681487083435,
      "learning_rate": 4.572067170642517e-05,
      "loss": 3.9485,
      "step": 100
    },
    {
      "ema_loss": 7.012274,
      "epoch": 0.09713453132588636,
      "grad_norm": 0.8234681487083435,
      "learning_rate": 4.572067170642517e-05,
      "loss": 3.9485,
      "min_ema_loss": 7.012274,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.14570179698882954,
      "grad_norm": 1.045837163925171,
      "learning_rate": 4.455313667817121e-05,
      "loss": 3.7226,
      "step": 150
    },
    {
      "ema_loss": 6.94648052,
      "epoch": 0.14570179698882954,
      "grad_norm": 1.045837163925171,
      "learning_rate": 4.455313667817121e-05,
      "loss": 3.7226,
      "min_ema_loss": 6.94648052,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.1942690626517727,
      "grad_norm": 1.0097405910491943,
      "learning_rate": 4.338560164991724e-05,
      "loss": 3.7564,
      "step": 200
    },
    {
      "ema_loss": 6.8826789096,
      "epoch": 0.1942690626517727,
      "grad_norm": 1.0097405910491943,
      "learning_rate": 4.338560164991724e-05,
      "loss": 3.7564,
      "min_ema_loss": 6.8826789096,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.1942690626517727,
      "eval_loss": 4.140468120574951,
      "eval_runtime": 155.203,
      "eval_samples_per_second": 23.582,
      "eval_steps_per_second": 1.475,
      "step": 200
    },
    {
      "epoch": 0.24283632831471588,
      "grad_norm": 1.0538450479507446,
      "learning_rate": 4.221806662166328e-05,
      "loss": 3.6946,
      "step": 250
    },
    {
      "ema_loss": 6.818917331408,
      "epoch": 0.24283632831471588,
      "grad_norm": 1.0538450479507446,
      "learning_rate": 4.221806662166328e-05,
      "loss": 3.6946,
      "min_ema_loss": 6.818917331408,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.2914035939776591,
      "grad_norm": 0.8788473010063171,
      "learning_rate": 4.105053159340932e-05,
      "loss": 3.7009,
      "step": 300
    },
    {
      "ema_loss": 6.756556984779839,
      "epoch": 0.2914035939776591,
      "grad_norm": 0.8788473010063171,
      "learning_rate": 4.105053159340932e-05,
      "loss": 3.7009,
      "min_ema_loss": 6.756556984779839,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.33997085964060225,
      "grad_norm": 0.8876953721046448,
      "learning_rate": 3.988299656515536e-05,
      "loss": 3.6559,
      "step": 350
    },
    {
      "ema_loss": 6.694543845084242,
      "epoch": 0.33997085964060225,
      "grad_norm": 0.8876953721046448,
      "learning_rate": 3.988299656515536e-05,
      "loss": 3.6559,
      "min_ema_loss": 6.694543845084242,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.3885381253035454,
      "grad_norm": 0.8005720376968384,
      "learning_rate": 3.8715461536901394e-05,
      "loss": 3.7454,
      "step": 400
    },
    {
      "ema_loss": 6.635560968182557,
      "epoch": 0.3885381253035454,
      "grad_norm": 0.8005720376968384,
      "learning_rate": 3.8715461536901394e-05,
      "loss": 3.7454,
      "min_ema_loss": 6.635560968182557,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.3885381253035454,
      "eval_loss": 4.119113445281982,
      "eval_runtime": 156.6637,
      "eval_samples_per_second": 23.362,
      "eval_steps_per_second": 1.462,
      "step": 400
    },
    {
      "epoch": 0.4371053909664886,
      "grad_norm": 0.9109161496162415,
      "learning_rate": 3.754792650864743e-05,
      "loss": 3.7312,
      "step": 450
    },
    {
      "ema_loss": 6.577473748818906,
      "epoch": 0.4371053909664886,
      "grad_norm": 0.9109161496162415,
      "learning_rate": 3.754792650864743e-05,
      "loss": 3.7312,
      "min_ema_loss": 6.577473748818906,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.48567265662943176,
      "grad_norm": 0.9222525954246521,
      "learning_rate": 3.6380391480393466e-05,
      "loss": 3.7668,
      "step": 500
    },
    {
      "ema_loss": 6.521260273842528,
      "epoch": 0.48567265662943176,
      "grad_norm": 0.9222525954246521,
      "learning_rate": 3.6380391480393466e-05,
      "loss": 3.7668,
      "min_ema_loss": 6.521260273842528,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.5342399222923749,
      "grad_norm": 0.7370977401733398,
      "learning_rate": 3.521285645213951e-05,
      "loss": 3.6739,
      "step": 550
    },
    {
      "ema_loss": 6.464313068365677,
      "epoch": 0.5342399222923749,
      "grad_norm": 0.7370977401733398,
      "learning_rate": 3.521285645213951e-05,
      "loss": 3.6739,
      "min_ema_loss": 6.464313068365677,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.5828071879553182,
      "grad_norm": 1.2507339715957642,
      "learning_rate": 3.4045321423885544e-05,
      "loss": 3.6877,
      "step": 600
    },
    {
      "ema_loss": 6.408780806998363,
      "epoch": 0.5828071879553182,
      "grad_norm": 1.2507339715957642,
      "learning_rate": 3.4045321423885544e-05,
      "loss": 3.6877,
      "min_ema_loss": 6.408780806998363,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.5828071879553182,
      "eval_loss": 4.095181941986084,
      "eval_runtime": 156.1073,
      "eval_samples_per_second": 23.445,
      "eval_steps_per_second": 1.467,
      "step": 600
    },
    {
      "epoch": 0.6313744536182613,
      "grad_norm": 0.892329216003418,
      "learning_rate": 3.287778639563158e-05,
      "loss": 3.6721,
      "step": 650
    },
    {
      "ema_loss": 6.354047190858396,
      "epoch": 0.6313744536182613,
      "grad_norm": 0.892329216003418,
      "learning_rate": 3.287778639563158e-05,
      "loss": 3.6721,
      "min_ema_loss": 6.354047190858396,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.6799417192812045,
      "grad_norm": 1.199617862701416,
      "learning_rate": 3.1710251367377616e-05,
      "loss": 3.6756,
      "step": 700
    },
    {
      "ema_loss": 6.300478247041228,
      "epoch": 0.6799417192812045,
      "grad_norm": 1.199617862701416,
      "learning_rate": 3.1710251367377616e-05,
      "loss": 3.6756,
      "min_ema_loss": 6.300478247041228,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.7285089849441476,
      "grad_norm": 1.1384669542312622,
      "learning_rate": 3.054271633912366e-05,
      "loss": 3.6235,
      "step": 750
    },
    {
      "ema_loss": 6.246938682100404,
      "epoch": 0.7285089849441476,
      "grad_norm": 1.1384669542312622,
      "learning_rate": 3.054271633912366e-05,
      "loss": 3.6235,
      "min_ema_loss": 6.246938682100404,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.7770762506070908,
      "grad_norm": 0.8697417974472046,
      "learning_rate": 2.93751813108697e-05,
      "loss": 3.6739,
      "step": 800
    },
    {
      "ema_loss": 6.195477908458395,
      "epoch": 0.7770762506070908,
      "grad_norm": 0.8697417974472046,
      "learning_rate": 2.93751813108697e-05,
      "loss": 3.6739,
      "min_ema_loss": 6.195477908458395,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.7770762506070908,
      "eval_loss": 4.092620849609375,
      "eval_runtime": 155.0481,
      "eval_samples_per_second": 23.606,
      "eval_steps_per_second": 1.477,
      "step": 800
    },
    {
      "epoch": 0.825643516270034,
      "grad_norm": 0.5860775709152222,
      "learning_rate": 2.8207646282615734e-05,
      "loss": 3.7062,
      "step": 850
    },
    {
      "ema_loss": 6.145692350289227,
      "epoch": 0.825643516270034,
      "grad_norm": 0.5860775709152222,
      "learning_rate": 2.8207646282615734e-05,
      "loss": 3.7062,
      "min_ema_loss": 6.145692350289227,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.8742107819329772,
      "grad_norm": 0.8428822755813599,
      "learning_rate": 2.704011125436177e-05,
      "loss": 3.66,
      "step": 900
    },
    {
      "ema_loss": 6.095978503283443,
      "epoch": 0.8742107819329772,
      "grad_norm": 0.8428822755813599,
      "learning_rate": 2.704011125436177e-05,
      "loss": 3.66,
      "min_ema_loss": 6.095978503283443,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.9227780475959203,
      "grad_norm": 0.7979889512062073,
      "learning_rate": 2.5872576226107806e-05,
      "loss": 3.6859,
      "step": 950
    },
    {
      "ema_loss": 6.047776933217775,
      "epoch": 0.9227780475959203,
      "grad_norm": 0.7979889512062073,
      "learning_rate": 2.5872576226107806e-05,
      "loss": 3.6859,
      "min_ema_loss": 6.047776933217775,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.9713453132588635,
      "grad_norm": 0.8380821943283081,
      "learning_rate": 2.470504119785385e-05,
      "loss": 3.6581,
      "step": 1000
    },
    {
      "ema_loss": 5.99998339455342,
      "epoch": 0.9713453132588635,
      "grad_norm": 0.8380821943283081,
      "learning_rate": 2.470504119785385e-05,
      "loss": 3.6581,
      "min_ema_loss": 5.99998339455342,
      "steps_without_improvement": 0
    },
    {
      "epoch": 0.9713453132588635,
      "eval_loss": 4.0790791511535645,
      "eval_runtime": 158.3056,
      "eval_samples_per_second": 23.12,
      "eval_steps_per_second": 1.447,
      "step": 1000
    },
    {
      "epoch": 1.0199125789218066,
      "grad_norm": 1.0662312507629395,
      "learning_rate": 2.3537506169599885e-05,
      "loss": 3.6806,
      "step": 1050
    },
    {
      "ema_loss": 5.953595726662351,
      "epoch": 1.0199125789218066,
      "grad_norm": 1.0662312507629395,
      "learning_rate": 2.3537506169599885e-05,
      "loss": 3.6806,
      "min_ema_loss": 5.953595726662351,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.0684798445847499,
      "grad_norm": 0.888639509677887,
      "learning_rate": 2.236997114134592e-05,
      "loss": 3.69,
      "step": 1100
    },
    {
      "ema_loss": 5.908323812129104,
      "epoch": 1.0684798445847499,
      "grad_norm": 0.888639509677887,
      "learning_rate": 2.236997114134592e-05,
      "loss": 3.69,
      "min_ema_loss": 5.908323812129104,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.117047110247693,
      "grad_norm": 0.5995603799819946,
      "learning_rate": 2.120243611309196e-05,
      "loss": 3.6462,
      "step": 1150
    },
    {
      "ema_loss": 5.863081335886522,
      "epoch": 1.117047110247693,
      "grad_norm": 0.5995603799819946,
      "learning_rate": 2.120243611309196e-05,
      "loss": 3.6462,
      "min_ema_loss": 5.863081335886522,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.1656143759106363,
      "grad_norm": 0.8672246336936951,
      "learning_rate": 2.0034901084837996e-05,
      "loss": 3.6308,
      "step": 1200
    },
    {
      "ema_loss": 5.818435709168792,
      "epoch": 1.1656143759106363,
      "grad_norm": 0.8672246336936951,
      "learning_rate": 2.0034901084837996e-05,
      "loss": 3.6308,
      "min_ema_loss": 5.818435709168792,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.1656143759106363,
      "eval_loss": 4.071132183074951,
      "eval_runtime": 155.106,
      "eval_samples_per_second": 23.597,
      "eval_steps_per_second": 1.476,
      "step": 1200
    },
    {
      "epoch": 1.2141816415735793,
      "grad_norm": 0.9874961376190186,
      "learning_rate": 1.8867366056584032e-05,
      "loss": 3.6317,
      "step": 1250
    },
    {
      "ema_loss": 5.774700994985416,
      "epoch": 1.2141816415735793,
      "grad_norm": 0.9874961376190186,
      "learning_rate": 1.8867366056584032e-05,
      "loss": 3.6317,
      "min_ema_loss": 5.774700994985416,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.2627489072365226,
      "grad_norm": 0.5931939482688904,
      "learning_rate": 1.769983102833007e-05,
      "loss": 3.5991,
      "step": 1300
    },
    {
      "ema_loss": 5.731188975085708,
      "epoch": 1.2627489072365226,
      "grad_norm": 0.5931939482688904,
      "learning_rate": 1.769983102833007e-05,
      "loss": 3.5991,
      "min_ema_loss": 5.731188975085708,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.3113161728994658,
      "grad_norm": 0.6955091953277588,
      "learning_rate": 1.6532296000076108e-05,
      "loss": 3.6527,
      "step": 1350
    },
    {
      "ema_loss": 5.689619195583993,
      "epoch": 1.3113161728994658,
      "grad_norm": 0.6955091953277588,
      "learning_rate": 1.6532296000076108e-05,
      "loss": 3.6527,
      "min_ema_loss": 5.689619195583993,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.359883438562409,
      "grad_norm": 0.8177025318145752,
      "learning_rate": 1.5364760971822147e-05,
      "loss": 3.6394,
      "step": 1400
    },
    {
      "ema_loss": 5.648614811672313,
      "epoch": 1.359883438562409,
      "grad_norm": 0.8177025318145752,
      "learning_rate": 1.5364760971822147e-05,
      "loss": 3.6394,
      "min_ema_loss": 5.648614811672313,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.359883438562409,
      "eval_loss": 4.069489002227783,
      "eval_runtime": 155.8808,
      "eval_samples_per_second": 23.479,
      "eval_steps_per_second": 1.469,
      "step": 1400
    },
    {
      "epoch": 1.408450704225352,
      "grad_norm": 0.7896800637245178,
      "learning_rate": 1.4197225943568183e-05,
      "loss": 3.7254,
      "step": 1450
    },
    {
      "ema_loss": 5.610150515438866,
      "epoch": 1.408450704225352,
      "grad_norm": 0.7896800637245178,
      "learning_rate": 1.4197225943568183e-05,
      "loss": 3.7254,
      "min_ema_loss": 5.610150515438866,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.4570179698882952,
      "grad_norm": 0.7222647666931152,
      "learning_rate": 1.3029690915314222e-05,
      "loss": 3.5533,
      "step": 1500
    },
    {
      "ema_loss": 5.569013505130089,
      "epoch": 1.4570179698882952,
      "grad_norm": 0.7222647666931152,
      "learning_rate": 1.3029690915314222e-05,
      "loss": 3.5533,
      "min_ema_loss": 5.569013505130089,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.5055852355512385,
      "grad_norm": 0.6010165214538574,
      "learning_rate": 1.1862155887060258e-05,
      "loss": 3.6316,
      "step": 1550
    },
    {
      "ema_loss": 5.530265235027487,
      "epoch": 1.5055852355512385,
      "grad_norm": 0.6010165214538574,
      "learning_rate": 1.1862155887060258e-05,
      "loss": 3.6316,
      "min_ema_loss": 5.530265235027487,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.5541525012141817,
      "grad_norm": 0.8206883072853088,
      "learning_rate": 1.0694620858806296e-05,
      "loss": 3.6327,
      "step": 1600
    },
    {
      "ema_loss": 5.4923139303269375,
      "epoch": 1.5541525012141817,
      "grad_norm": 0.8206883072853088,
      "learning_rate": 1.0694620858806296e-05,
      "loss": 3.6327,
      "min_ema_loss": 5.4923139303269375,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.5541525012141817,
      "eval_loss": 4.060727596282959,
      "eval_runtime": 155.3933,
      "eval_samples_per_second": 23.553,
      "eval_steps_per_second": 1.474,
      "step": 1600
    },
    {
      "epoch": 1.602719766877125,
      "grad_norm": 0.7945390343666077,
      "learning_rate": 9.527085830552334e-06,
      "loss": 3.6911,
      "step": 1650
    },
    {
      "ema_loss": 5.4562896517203985,
      "epoch": 1.602719766877125,
      "grad_norm": 0.7945390343666077,
      "learning_rate": 9.527085830552334e-06,
      "loss": 3.6911,
      "min_ema_loss": 5.4562896517203985,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.651287032540068,
      "grad_norm": 0.8261608481407166,
      "learning_rate": 8.359550802298371e-06,
      "loss": 3.6366,
      "step": 1700
    },
    {
      "ema_loss": 5.41989585868599,
      "epoch": 1.651287032540068,
      "grad_norm": 0.8261608481407166,
      "learning_rate": 8.359550802298371e-06,
      "loss": 3.6366,
      "min_ema_loss": 5.41989585868599,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.6998542982030111,
      "grad_norm": 0.9511308073997498,
      "learning_rate": 7.192015774044408e-06,
      "loss": 3.6914,
      "step": 1750
    },
    {
      "ema_loss": 5.38532594151227,
      "epoch": 1.6998542982030111,
      "grad_norm": 0.9511308073997498,
      "learning_rate": 7.192015774044408e-06,
      "loss": 3.6914,
      "min_ema_loss": 5.38532594151227,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.7484215638659544,
      "grad_norm": 0.7271257638931274,
      "learning_rate": 6.0244807457904465e-06,
      "loss": 3.6377,
      "step": 1800
    },
    {
      "ema_loss": 5.350373422682024,
      "epoch": 1.7484215638659544,
      "grad_norm": 0.7271257638931274,
      "learning_rate": 6.0244807457904465e-06,
      "loss": 3.6377,
      "min_ema_loss": 5.350373422682024,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.7484215638659544,
      "eval_loss": 4.062851905822754,
      "eval_runtime": 155.2753,
      "eval_samples_per_second": 23.571,
      "eval_steps_per_second": 1.475,
      "step": 1800
    },
    {
      "epoch": 1.7969888295288974,
      "grad_norm": 0.7518597841262817,
      "learning_rate": 4.856945717536484e-06,
      "loss": 3.6354,
      "step": 1850
    },
    {
      "ema_loss": 5.316073954228384,
      "epoch": 1.7969888295288974,
      "grad_norm": 0.7518597841262817,
      "learning_rate": 4.856945717536484e-06,
      "loss": 3.6354,
      "min_ema_loss": 5.316073954228384,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.8455560951918408,
      "grad_norm": 0.7228637933731079,
      "learning_rate": 3.6894106892825214e-06,
      "loss": 3.6494,
      "step": 1900
    },
    {
      "ema_loss": 5.282740475143816,
      "epoch": 1.8455560951918408,
      "grad_norm": 0.7228637933731079,
      "learning_rate": 3.6894106892825214e-06,
      "loss": 3.6494,
      "min_ema_loss": 5.282740475143816,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.8941233608547838,
      "grad_norm": 0.6856203675270081,
      "learning_rate": 2.521875661028559e-06,
      "loss": 3.635,
      "step": 1950
    },
    {
      "ema_loss": 5.24978566564094,
      "epoch": 1.8941233608547838,
      "grad_norm": 0.6856203675270081,
      "learning_rate": 2.521875661028559e-06,
      "loss": 3.635,
      "min_ema_loss": 5.24978566564094,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.942690626517727,
      "grad_norm": 0.740358829498291,
      "learning_rate": 1.3543406327745965e-06,
      "loss": 3.6697,
      "step": 2000
    },
    {
      "ema_loss": 5.218183952328121,
      "epoch": 1.942690626517727,
      "grad_norm": 0.740358829498291,
      "learning_rate": 1.3543406327745965e-06,
      "loss": 3.6697,
      "min_ema_loss": 5.218183952328121,
      "steps_without_improvement": 0
    },
    {
      "epoch": 1.942690626517727,
      "eval_loss": 4.057548999786377,
      "eval_runtime": 155.1509,
      "eval_samples_per_second": 23.59,
      "eval_steps_per_second": 1.476,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 2058,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.999998749158093e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
